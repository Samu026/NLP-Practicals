{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a02b4db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, TreebankWordTokenizer, TweetTokenizer, MWETokenizer\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ff7d09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Samruddhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Samruddhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Samruddhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32d5eb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Text\n",
    "text = \"NLTK is a leading platform for building Python programs to work with human language data. It's awesome, isn't it?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b783a2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      "NLTK is a leading platform for building Python programs to work with human language data. It's awesome, isn't it?\n"
     ]
    }
   ],
   "source": [
    "# 1. TOKENIZATION\n",
    "print(\"Original Text:\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d0e5750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Whitespace Tokenization:\n",
      "['NLTK', 'is', 'a', 'leading', 'platform', 'for', 'building', 'Python', 'programs', 'to', 'work', 'with', 'human', 'language', 'data.', \"It's\", 'awesome,', \"isn't\", 'it?']\n"
     ]
    }
   ],
   "source": [
    "# Whitespace Tokenization\n",
    "whitespace_tokens = text.split()\n",
    "print(\"\\nWhitespace Tokenization:\")\n",
    "print(whitespace_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ccdc1d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Punctuation-based Tokenization:\n",
      "['NLTK', 'is', 'a', 'leading', 'platform', 'for', 'building', 'Python', 'programs', 'to', 'work', 'with', 'human', 'language', 'data', '.', 'It', \"'\", 's', 'awesome', ',', 'isn', \"'\", 't', 'it', '?']\n"
     ]
    }
   ],
   "source": [
    "# Punctuation-based Tokenization (using regex)\n",
    "punct_tokens = re.findall(r'\\w+|[^\\w\\s]', text)\n",
    "print(\"\\nPunctuation-based Tokenization:\")\n",
    "print(punct_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e541b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Treebank Tokenizer:\n",
      "['NLTK', 'is', 'a', 'leading', 'platform', 'for', 'building', 'Python', 'programs', 'to', 'work', 'with', 'human', 'language', 'data.', 'It', \"'s\", 'awesome', ',', 'is', \"n't\", 'it', '?']\n"
     ]
    }
   ],
   "source": [
    "# Treebank Tokenizer\n",
    "treebank_tokenizer = TreebankWordTokenizer()\n",
    "treebank_tokens = treebank_tokenizer.tokenize(text)\n",
    "print(\"\\nTreebank Tokenizer:\")\n",
    "print(treebank_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ccfbce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tweet Tokenizer:\n",
      "['NLTK', 'is', 'a', 'leading', 'platform', 'for', 'building', 'Python', 'programs', 'to', 'work', 'with', 'human', 'language', 'data', '.', \"It's\", 'awesome', ',', \"isn't\", 'it', '?']\n"
     ]
    }
   ],
   "source": [
    "# Tweet Tokenizer\n",
    "tweet_tokenizer = TweetTokenizer()\n",
    "tweet_tokens = tweet_tokenizer.tokenize(text)\n",
    "print(\"\\nTweet Tokenizer:\")\n",
    "print(tweet_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62eda50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Multi-Word Expression (MWE) Tokenizer:\n",
      "['NLTK_is', 'a', 'leading', 'platform', 'for', 'building', 'Python', 'programs', 'to', 'work', 'with', 'human_language', 'data', '.', 'It', \"'s\", 'awesome', ',', 'is', \"n't\", 'it', '?']\n"
     ]
    }
   ],
   "source": [
    "# MWE Tokenizer\n",
    "mwe_tokenizer = MWETokenizer([('human', 'language'), ('NLTK', 'is')])\n",
    "mwe_tokens = mwe_tokenizer.tokenize(word_tokenize(text))\n",
    "print(\"\\nMulti-Word Expression (MWE) Tokenizer:\")\n",
    "print(mwe_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9104d32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Porter Stemmer:\n",
      "['nltk', 'is', 'a', 'lead', 'platform', 'for', 'build', 'python', 'program', 'to', 'work', 'with', 'human', 'languag', 'data', '.', 'it', \"'s\", 'awesom', ',', 'is', \"n't\", 'it', '?']\n"
     ]
    }
   ],
   "source": [
    "# 2. STEMMING\n",
    "\n",
    "# Porter Stemmer\n",
    "porter = PorterStemmer()\n",
    "porter_stems = [porter.stem(word) for word in word_tokenize(text)]\n",
    "print(\"\\nPorter Stemmer:\")\n",
    "print(porter_stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de1eb37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Snowball Stemmer:\n",
      "['nltk', 'is', 'a', 'lead', 'platform', 'for', 'build', 'python', 'program', 'to', 'work', 'with', 'human', 'languag', 'data', '.', 'it', \"'s\", 'awesom', ',', 'is', \"n't\", 'it', '?']\n"
     ]
    }
   ],
   "source": [
    "# Snowball Stemmer\n",
    "snowball = SnowballStemmer(\"english\")\n",
    "snowball_stems = [snowball.stem(word) for word in word_tokenize(text)]\n",
    "print(\"\\nSnowball Stemmer:\")\n",
    "print(snowball_stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f9e80b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lemmatized Words:\n",
      "['NLTK', 'is', 'a', 'leading', 'platform', 'for', 'building', 'Python', 'program', 'to', 'work', 'with', 'human', 'language', 'data', '.', 'It', \"'s\", 'awesome', ',', 'is', \"n't\", 'it', '?']\n"
     ]
    }
   ],
   "source": [
    "# 3. LEMMATIZATION\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in word_tokenize(text)]\n",
    "print(\"\\nLemmatized Words:\")\n",
    "print(lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499be33d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
