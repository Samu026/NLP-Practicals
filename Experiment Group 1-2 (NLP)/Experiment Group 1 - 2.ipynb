{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eda684f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.preprocessing import normalize\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "762374ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data\n",
    "corpus = [\n",
    "    \"I love machine learning and data science\",\n",
    "    \"Data science is fun and exciting\",\n",
    "    \"Machine learning is a key skill in AI\",\n",
    "    \"I enjoy learning new things\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b215e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words - Count Occurrence:\n",
      "    ai  and  data  enjoy  exciting  fun  in  is  key  learning  love  machine  \\\n",
      "0   0    1     1      0         0    0   0   0    0         1     1        1   \n",
      "1   0    1     1      0         1    1   0   1    0         0     0        0   \n",
      "2   1    0     0      0         0    0   1   1    1         1     0        1   \n",
      "3   0    0     0      1         0    0   0   0    0         1     0        0   \n",
      "\n",
      "   new  science  skill  things  \n",
      "0    0        1      0       0  \n",
      "1    0        1      0       0  \n",
      "2    0        0      1       0  \n",
      "3    1        0      0       1  \n"
     ]
    }
   ],
   "source": [
    "# Bag-of-Words (Count Occurrence)\n",
    "count_occurrence = CountVectorizer()\n",
    "X_count = count_occurrence.fit_transform(corpus)\n",
    "df_count = pd.DataFrame(X_count.toarray(), columns=count_occurrence.get_feature_names_out())\n",
    "print(\"Bag of Words - Count Occurrence:\\n\", df_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82fb1ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bag of Words - Normalized Count Occurrence:\n",
      "          ai       and      data  enjoy  exciting       fun        in  \\\n",
      "0  0.000000  0.166667  0.166667   0.00  0.000000  0.000000  0.000000   \n",
      "1  0.000000  0.166667  0.166667   0.00  0.166667  0.166667  0.000000   \n",
      "2  0.142857  0.000000  0.000000   0.00  0.000000  0.000000  0.142857   \n",
      "3  0.000000  0.000000  0.000000   0.25  0.000000  0.000000  0.000000   \n",
      "\n",
      "         is       key  learning      love   machine   new   science     skill  \\\n",
      "0  0.000000  0.000000  0.166667  0.166667  0.166667  0.00  0.166667  0.000000   \n",
      "1  0.166667  0.000000  0.000000  0.000000  0.000000  0.00  0.166667  0.000000   \n",
      "2  0.142857  0.142857  0.142857  0.000000  0.142857  0.00  0.000000  0.142857   \n",
      "3  0.000000  0.000000  0.250000  0.000000  0.000000  0.25  0.000000  0.000000   \n",
      "\n",
      "   things  \n",
      "0    0.00  \n",
      "1    0.00  \n",
      "2    0.00  \n",
      "3    0.25  \n"
     ]
    }
   ],
   "source": [
    "# Normalized Count Occurrence (L1 norm)\n",
    "X_count_norm = normalize(X_count, norm='l1')\n",
    "df_count_norm = pd.DataFrame(X_count_norm.toarray(), columns=count_occurrence.get_feature_names_out())\n",
    "print(\"\\nBag of Words - Normalized Count Occurrence:\\n\", df_count_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f21637d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF:\n",
      "          ai       and      data     enjoy  exciting      fun        in  \\\n",
      "0  0.000000  0.399546  0.399546  0.000000   0.00000  0.00000  0.000000   \n",
      "1  0.000000  0.372225  0.372225  0.000000   0.47212  0.47212  0.000000   \n",
      "2  0.420681  0.000000  0.000000  0.000000   0.00000  0.00000  0.420681   \n",
      "3  0.000000  0.000000  0.000000  0.541736   0.00000  0.00000  0.000000   \n",
      "\n",
      "         is       key  learning      love   machine       new   science  \\\n",
      "0  0.000000  0.000000  0.323467  0.506774  0.399546  0.000000  0.399546   \n",
      "1  0.372225  0.000000  0.000000  0.000000  0.000000  0.000000  0.372225   \n",
      "2  0.331670  0.420681  0.268515  0.000000  0.331670  0.000000  0.000000   \n",
      "3  0.000000  0.000000  0.345783  0.000000  0.000000  0.541736  0.000000   \n",
      "\n",
      "      skill    things  \n",
      "0  0.000000  0.000000  \n",
      "1  0.000000  0.000000  \n",
      "2  0.420681  0.000000  \n",
      "3  0.000000  0.541736  \n"
     ]
    }
   ],
   "source": [
    "# TF-IDF\n",
    "tfidf_occurrence = TfidfVectorizer()\n",
    "X_tfidf = tfidf_occurrence.fit_transform(corpus)\n",
    "df_tfidf = pd.DataFrame(X_tfidf.toarray(), columns=tfidf_occurrence.get_feature_names_out())\n",
    "print(\"\\nTF-IDF:\\n\", df_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97fce0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec Embeddings\n",
    "tokenized_corpus = [sentence.lower().split() for sentence in corpus]\n",
    "w2v_model = Word2Vec(sentences=tokenized_corpus, vector_size=50, window=2, min_count=1, workers=1, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec98e006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word2Vec Embeddings for word 'learning':\n",
      " [-1.07199990e-03  4.72599320e-04  1.02075171e-02  1.80195551e-02\n",
      " -1.86056513e-02 -1.42333433e-02  1.29171927e-02  1.79462414e-02\n",
      " -1.00304112e-02 -7.52587756e-03  1.47622460e-02 -3.06692114e-03\n",
      " -9.07294545e-03  1.31098200e-02 -9.72019415e-03 -3.63100530e-03\n",
      "  5.75345429e-03  1.98484841e-03 -1.65706240e-02 -1.88982189e-02\n",
      "  1.46249318e-02  1.01408092e-02  1.35151129e-02  1.52485142e-03\n",
      "  1.27026178e-02 -6.81040483e-03 -1.89279346e-03  1.15381200e-02\n",
      " -1.50436601e-02 -7.87345599e-03 -1.50244525e-02 -1.85924501e-03\n",
      "  1.90767795e-02 -1.46377487e-02 -4.66758432e-03 -3.87661578e-03\n",
      "  1.61548574e-02 -1.18620954e-02  9.02669344e-05 -9.50748939e-03\n",
      " -1.92084312e-02  1.00153638e-02 -1.75192691e-02 -8.78333300e-03\n",
      " -7.02316029e-05 -5.92096709e-04 -1.53229153e-02  1.92290172e-02\n",
      "  9.96463653e-03  1.84666868e-02]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nWord2Vec Embeddings for word 'learning':\\n\", w2v_model.wv['learning'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0138bfc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Word2Vec Embedding for each sentence:\n",
      "          0         1         2         3         4         5         6   \\\n",
      "0 -0.004315  0.000160 -0.004318  0.002177  0.002283 -0.000606  0.004791   \n",
      "1 -0.002559  0.000874 -0.005111 -0.007262 -0.000969  0.000705  0.004257   \n",
      "2 -0.001829 -0.003584  0.006683  0.006456 -0.006254 -0.003310  0.004823   \n",
      "3 -0.003987  0.007239  0.002202  0.001972 -0.000679 -0.006440  0.005232   \n",
      "\n",
      "         7         8         9   ...        40        41        42        43  \\\n",
      "0  0.004340 -0.008858  0.004825  ... -0.002088 -0.000790 -0.003911 -0.000193   \n",
      "1  0.005389 -0.003318 -0.003677  ... -0.000372  0.001598  0.004124 -0.003931   \n",
      "2  0.001387 -0.005990 -0.008739  ...  0.006626  0.000103 -0.006082 -0.002109   \n",
      "3 -0.000755 -0.004322 -0.000373  ... -0.005865  0.001220 -0.000360 -0.004869   \n",
      "\n",
      "         44        45        46        47        48        49  \n",
      "0  0.006258  0.005233  0.001550 -0.000956  0.001853  0.001929  \n",
      "1  0.008566  0.006844  0.005785  0.002550 -0.001199 -0.004374  \n",
      "2  0.005876  0.004860 -0.002172 -0.006537  0.003387  0.000366  \n",
      "3  0.008341 -0.002164 -0.001556  0.001644 -0.000035  0.003703  \n",
      "\n",
      "[4 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "# Average Word2Vec vector for each sentence\n",
    "def average_vector(sentence, model):\n",
    "    words = sentence.lower().split()\n",
    "    vectors = [model.wv[word] for word in words if word in model.wv]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)\n",
    "\n",
    "sentence_vectors = np.array([average_vector(sent, w2v_model) for sent in corpus])\n",
    "print(\"\\nAverage Word2Vec Embedding for each sentence:\\n\", pd.DataFrame(sentence_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583ae598",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
