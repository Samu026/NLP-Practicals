{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "01388ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import joblib\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "11993584",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Samruddhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Samruddhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Samruddhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5ce3dfb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step Original Data:\n",
      "                                     text   label\n",
      "0        Cats are running in the garden!  animal\n",
      "1        The dog barked loudly at night.  animal\n",
      "2       Birds are flying over the hills.  animal\n",
      "3  She is reading a book on the balcony.   human \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Create sample data\n",
    "data = {\n",
    "    'text': [\n",
    "        \"Cats are running in the garden!\",\n",
    "        \"The dog barked loudly at night.\",\n",
    "        \"Birds are flying over the hills.\",\n",
    "        \"She is reading a book on the balcony.\",\n",
    "    ],\n",
    "    'label': ['animal', 'animal', 'animal', 'human']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Step Original Data:\\n\", df, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "422e2ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step Cleaned Text:\n",
      "                                     text                            clean_text\n",
      "0        Cats are running in the garden!        cats are running in the garden\n",
      "1        The dog barked loudly at night.        the dog barked loudly at night\n",
      "2       Birds are flying over the hills.       birds are flying over the hills\n",
      "3  She is reading a book on the balcony.  she is reading a book on the balcony \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Clean text\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "df['clean_text'] = df['text'].apply(clean_text)\n",
    "print(\"Step Cleaned Text:\\n\", df[['text', 'clean_text']], \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5ff584c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned data\n",
    "df[['text', 'clean_text']].to_csv('step4_cleaned_text.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d4370f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step Processed Text (lemmatized & stopwords removed):\n",
      "                              clean_text           processed_text\n",
      "0        cats are running in the garden       cat running garden\n",
      "1        the dog barked loudly at night  dog barked loudly night\n",
      "2       birds are flying over the hills         bird flying hill\n",
      "3  she is reading a book on the balcony     reading book balcony \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Lemmatization & Stop word removal\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    lemmatized = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    return ' '.join(lemmatized)\n",
    "\n",
    "df['processed_text'] = df['clean_text'].apply(preprocess_text)\n",
    "print(\"Step Processed Text (lemmatized & stopwords removed):\\n\", df[['clean_text', 'processed_text']], \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3cee5b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed data\n",
    "df[['text', 'processed_text']].to_csv('step5_processed_text.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ff42c7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step Encoded Labels:\n",
      "     label  label_encoded\n",
      "0  animal              0\n",
      "1  animal              0\n",
      "2  animal              0\n",
      "3   human              1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "df['label_encoded'] = label_encoder.fit_transform(df['label'])\n",
    "print(\"Step Encoded Labels:\\n\", df[['label', 'label_encoded']], \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "02c28438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save label encoder and encoded labels\n",
    "joblib.dump(label_encoder, 'step6_label_encoder.pkl')\n",
    "df[['label', 'label_encoded']].to_csv('step6_label_encoded.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0e25e836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step TF-IDF Matrix (Top 5 rows):\n",
      "    balcony  barked     bird     book      cat  dog   flying   garden     hill  \\\n",
      "0  0.00000     0.0  0.00000  0.00000  0.57735  0.0  0.00000  0.57735  0.00000   \n",
      "1  0.00000     0.5  0.00000  0.00000  0.00000  0.5  0.00000  0.00000  0.00000   \n",
      "2  0.00000     0.0  0.57735  0.00000  0.00000  0.0  0.57735  0.00000  0.57735   \n",
      "3  0.57735     0.0  0.00000  0.57735  0.00000  0.0  0.00000  0.00000  0.00000   \n",
      "\n",
      "   loudly  night  reading  running  \n",
      "0     0.0    0.0  0.00000  0.57735  \n",
      "1     0.5    0.5  0.00000  0.00000  \n",
      "2     0.0    0.0  0.00000  0.00000  \n",
      "3     0.0    0.0  0.57735  0.00000   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 7: TF-IDF Vectorization\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(df['processed_text'])\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf.get_feature_names_out())\n",
    "print(\"Step TF-IDF Matrix (Top 5 rows):\\n\", tfidf_df.head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dc011300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['step7_tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save TF-IDF matrix and vectorizer\n",
    "tfidf_df.to_csv('step7_tfidf_matrix.csv', index=False)\n",
    "joblib.dump(tfidf, 'step7_tfidf_vectorizer.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "30334e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " All steps completed and outputs saved successfully!\n",
      "\n",
      " Files Saved:\n",
      "- step4_cleaned_text.csv\n",
      "- step5_processed_text.csv\n",
      "- step6_label_encoded.csv\n",
      "- step6_label_encoder.pkl\n",
      "- step7_tfidf_matrix.csv\n",
      "- step7_tfidf_vectorizer.pkl\n"
     ]
    }
   ],
   "source": [
    "# Final saved output summary\n",
    "print(\" All steps completed and outputs saved successfully!\\n\")\n",
    "print(\" Files Saved:\")\n",
    "print(\"- step4_cleaned_text.csv\")\n",
    "print(\"- step5_processed_text.csv\")\n",
    "print(\"- step6_label_encoded.csv\")\n",
    "print(\"- step6_label_encoder.pkl\")\n",
    "print(\"- step7_tfidf_matrix.csv\")\n",
    "print(\"- step7_tfidf_vectorizer.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
